{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01101b5c-1de3-4994-b18a-cdf2be00a02b",
   "metadata": {},
   "source": [
    "# ¿Que más se podría hacer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b963aa-4120-4880-bfdc-274133cf50b0",
   "metadata": {},
   "source": [
    "- Test con data augmentation y la LSTM\n",
    "- Usar los tokenizadores usados en los transformers para ver como funcionan\n",
    "- TSNE de embeddings y analizar si hay interpretación\n",
    "- Probar con otras encimas o proteinas\n",
    "- Usar los embeddings entrenados para analizar resultados de proteinas o encimas con menos data\n",
    "- Entrenar una red neuronal con los features (fingerprints por ejemplo) y comparar los resultados con los embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a0a2b8-eccc-45db-8ccf-4bb9dd5ca344",
   "metadata": {},
   "source": [
    "# Tome cualquiera de estas propuestas o alguna suya y desarrolle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac13f6c-a061-4c24-a5fc-081ea6283a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab7de8-eb23-47d7-a771-28a2397d0a54",
   "metadata": {},
   "source": [
    "# Modelo LSTM con generador, embedings de smiles y data-augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21bee0a3-79a7-43b2-9ac2-15cad5630e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 06:39:58.089878: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-31 06:39:58.092950: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-31 06:39:58.170496: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-31 06:39:58.171784: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-31 06:39:59.240098: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datagen import smiles_dict, smiles_to_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aa799f-b75c-4d23-869b-fea6d041a6e9",
   "metadata": {},
   "source": [
    "### smiles_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "628a3149-eabe-4de3-8404-d86eb6ad3baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(smiles_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c9312c-4232-414c-b0ff-1e6fb6dba1a6",
   "metadata": {},
   "source": [
    "smiles_dict nos da un tokenizador para simplificar el problema. Puede ver como se construyó en la notebook **deep_chem**.\n",
    "Si al momento de correr el modelo con este diccionario encuentra problemas de key_error, puede agregar los faltantes al diccionario\n",
    "\n",
    "Mirar dentro de **datagen.py** como se usa este diccionario con la función **smiles_to_seq** para tokenizar. El código es muy sencillo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e29ef48f-4b67-42a4-83af-e7d0bb980c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'#': 1, '(': 2, ')': 3, '+': 4, '-': 5, '/': 6, '1': 7, '2': 8, '3': 9, '4': 10, '5': 11, '6': 12, '7': 13, '8': 14, '=': 15, 'C': 16, 'F': 17, 'H': 18, 'I': 19, 'N': 20, 'O': 21, 'P': 22, 'S': 23, '[': 24, '\\\\': 25, ']': 26, '_': 27, 'c': 28, 'Cl': 29, 'Br': 30, 'n': 31, 'o': 32, 's': 33, '@': 34, '.': 35, 'a': 36, 'B': 37, 'e': 38, 'i': 39, '9': 40, '10': 41, '11': 42}\n"
     ]
    }
   ],
   "source": [
    "print(smiles_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b103a4e0-038d-406b-aab8-5c9452ede04e",
   "metadata": {},
   "source": [
    "# Carga de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "353a2d75-f0f4-4563-9842-c68d77118161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/acetylcholinesterase_02_bioactivity_data_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e7fcdcb-ad53-4ebf-bc17-a241c79269da",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_idx = df['canonical_smiles'].apply(len).argmax()\n",
    "min_len_idx = df['canonical_smiles'].apply(len).argmin()\n",
    "max_sequence_len = len(df['canonical_smiles'].iloc[max_len_idx]) + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1554fa5-d9ee-456c-be20-80571e319fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_chembl_id</th>\n",
       "      <th>canonical_smiles</th>\n",
       "      <th>standard_value</th>\n",
       "      <th>standard_value_norm</th>\n",
       "      <th>pIC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL133897</td>\n",
       "      <td>CCOc1nn(-c2cccc(OCc3ccccc3)c2)c(=O)o1</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>6.124939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL336398</td>\n",
       "      <td>O=C(N1CCCCC1)n1nc(-c2ccc(Cl)cc2)nc1SCC1CC1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL131588</td>\n",
       "      <td>CN(C(=O)n1nc(-c2ccc(Cl)cc2)nc1SCC(F)(F)F)c1ccccc1</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>4.301030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL130628</td>\n",
       "      <td>O=C(N1CCCCC1)n1nc(-c2ccc(Cl)cc2)nc1SCC(F)(F)F</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL130478</td>\n",
       "      <td>CSc1nc(-c2ccc(OC(F)(F)F)cc2)nn1C(=O)N(C)C</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>6.096910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  molecule_chembl_id                                   canonical_smiles  \\\n",
       "0       CHEMBL133897              CCOc1nn(-c2cccc(OCc3ccccc3)c2)c(=O)o1   \n",
       "1       CHEMBL336398         O=C(N1CCCCC1)n1nc(-c2ccc(Cl)cc2)nc1SCC1CC1   \n",
       "2       CHEMBL131588  CN(C(=O)n1nc(-c2ccc(Cl)cc2)nc1SCC(F)(F)F)c1ccccc1   \n",
       "3       CHEMBL130628      O=C(N1CCCCC1)n1nc(-c2ccc(Cl)cc2)nc1SCC(F)(F)F   \n",
       "4       CHEMBL130478          CSc1nc(-c2ccc(OC(F)(F)F)cc2)nn1C(=O)N(C)C   \n",
       "\n",
       "   standard_value  standard_value_norm     pIC50  \n",
       "0           750.0                750.0  6.124939  \n",
       "1           100.0                100.0  7.000000  \n",
       "2         50000.0              50000.0  4.301030  \n",
       "3           300.0                300.0  6.522879  \n",
       "4           800.0                800.0  6.096910  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9675f7e8-a8e6-44ff-b1c5-b229cbbeb2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['canonical_smiles'].values\n",
    "y = df['pIC50'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd87900d-dca2-4f0e-a5c2-58fef4266a67",
   "metadata": {},
   "source": [
    "# Data augmentation:\n",
    "\n",
    "https://arxiv.org/pdf/1703.07076.pdf\n",
    "\n",
    "https://github.com/EBjerrum/molvecgen\n",
    "\n",
    "https://github.com/Ebjerrum/SMILES-enumeration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605fb205-e7e7-45fb-99bd-2e6f490977a8",
   "metadata": {},
   "source": [
    "En la publicación de arriba se describe una técnica de aumentación de datos para los smiles. Leerla si es de su interes (Opcional)\n",
    "\n",
    "En el módulo **dataug.py**, tomando como referencia los repositorios arriba citados se implementó la aumentación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd51b313-2eda-4b2f-b876-7ddf27fae055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o1c(=O)n(-c2cccc(OCc3ccccc3)c2)nc1OCC\n",
      "c1c(COc2cc(-n3nc(OCC)oc3=O)ccc2)cccc1\n",
      "C(Oc1oc(=O)n(-c2cc(OCc3ccccc3)ccc2)n1)C\n",
      "C(C)Oc1oc(=O)n(-c2cc(OCc3ccccc3)ccc2)n1\n",
      "O=c1n(-c2cc(OCc3ccccc3)ccc2)nc(OCC)o1\n",
      "O(Cc1ccccc1)c1cc(-n2nc(OCC)oc2=O)ccc1\n",
      "n1c(OCC)oc(=O)n1-c1cc(OCc2ccccc2)ccc1\n",
      "O(c1cc(-n2nc(OCC)oc2=O)ccc1)Cc1ccccc1\n",
      "CCOc1nn(-c2cc(OCc3ccccc3)ccc2)c(=O)o1\n",
      "C(Oc1cc(-n2c(=O)oc(OCC)n2)ccc1)c1ccccc1\n"
     ]
    }
   ],
   "source": [
    "seq = 'CCOc1nn(-c2cccc(OCc3ccccc3)c2)c(=O)o1'\n",
    "\n",
    "from dataaug import SmilesEnumerator\n",
    "sme = SmilesEnumerator()\n",
    "for i in range(10):\n",
    "    print(sme.randomize_smiles('CCOc1nn(-c2cccc(OCc3ccccc3)c2)c(=O)o1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4733af9-9c49-4c2f-bb1d-dc7f180cc66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1cc(COc2cccc(-n3c(=O)oc(OCC)n3)c2)ccc1\n",
      "c1(OCc2ccccc2)cc(-n2nc(OCC)oc2=O)ccc1\n",
      "c1(=O)oc(OCC)nn1-c1cccc(OCc2ccccc2)c1\n",
      "c1(-n2c(=O)oc(OCC)n2)cccc(OCc2ccccc2)c1\n",
      "c1(OCc2ccccc2)cccc(-n2nc(OCC)oc2=O)c1\n",
      "c1c(OCc2ccccc2)cc(-n2c(=O)oc(OCC)n2)cc1\n",
      "c1cc(OCc2ccccc2)cc(-n2nc(OCC)oc2=O)c1\n",
      "c1ccc(-n2c(=O)oc(OCC)n2)cc1OCc1ccccc1\n",
      "c1(=O)n(-c2cc(OCc3ccccc3)ccc2)nc(OCC)o1\n",
      "c1ccc(COc2cccc(-n3c(=O)oc(OCC)n3)c2)cc1\n"
     ]
    }
   ],
   "source": [
    "from dataaug import SmilesEnumerator\n",
    "sme = SmilesEnumerator()\n",
    "for i in range(10):\n",
    "    print(sme.randomize_smiles('CCOc1nn(-c2cccc(OCc3ccccc3)c2)c(=O)o1'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1923d3-1df0-4df1-a43c-ec30eff6fe4d",
   "metadata": {},
   "source": [
    "# DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6a3c67-9f44-4052-9e93-9e274f08c1b5",
   "metadata": {},
   "source": [
    "Construir un generador al que se le pase al instanciarlo:\n",
    "- X: smiles (formula química)\n",
    "- y: pIC50\n",
    "- batch_size\n",
    "- max_sequence_len (int): La máxima longitud de las secuencias (para hacer el padding)\n",
    "- data_augmentation (boolean): si quiero hacer o no data-augmentation. \n",
    "- shuffle (boolean)\n",
    "\n",
    "Guardarlo en el módulo **datagen.py** con el nombre de la clase **DataGenerator**\n",
    "\n",
    "Notar que el módulo **datagen.py** ya tiene una estructura para completar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f602f3e4-24aa-41ee-9f83-89ec3acc96f1",
   "metadata": {},
   "source": [
    "### Importamos el módulo y lo probamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "413bce05-2685-4c84-8a43-c3dd8ed74e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datagen import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52aa520a-a84b-4d8b-a22e-6b4a5cc7e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgen = DataGenerator(X, y, max_sequence_len, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3212e31-dd2c-4ebc-b9a0-78ed4bb5d78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6160"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dgen) * dgen.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "133033ed-a3b1-4572-aaaf-f4cb2a055724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\r"
     ]
    }
   ],
   "source": [
    "for i, (X_b, y_b) in enumerate(dgen):\n",
    "    print(f'{i}\\r', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d010f566-c375-4518-879f-d087fc2cb7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  7,  2, ...,  0,  0,  0],\n",
       "       [28,  7,  8, ...,  0,  0,  0],\n",
       "       [21, 15, 16, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [20,  2, 16, ...,  0,  0,  0],\n",
       "       [16,  2, 20, ...,  0,  0,  0],\n",
       "       [28,  7, 28, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b29b7246-142c-4401-b44e-9815c4bf9370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4233710d-9274-4dae-b22d-cf42b57ad862",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce7a95e6-2486-42fb-97fb-865e3fd6a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcb9840f-2f41-45be-99a5-f05f3ab73ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb13b9d2-cd84-4015-a5f4-cf51e8449f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4925,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "649277c5-fda5-457c-985d-51a426882c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:4500]\n",
    "y_train = y_train[:4500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ad17134-3e15-42d1-b8c9-0c793169e145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 4500, 1232)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "929de60c-7128-4e35-8efc-4b5f9ee9471c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['COc1cc(/C=C/c2ccc3ccccc3[n+]2C)ccc1N1CCOCC1.[I-]',\n",
       "       'CCCCCCCNC(=O)Oc1ccc2c(c1)C1(C)CCN(CC)C2C1',\n",
       "       'c1ccc2c(COc3nn(CCN4CCCC4)c4ccccc34)cccc2c1', ...,\n",
       "       'Cl.Nc1c2c(nc3ccc(F)cc13)CCC2',\n",
       "       'CCN(CC)CCCCCOc1ccc(C(=O)/C=C/c2ccccc2)cc1',\n",
       "       'COc1ccccc1/C=C1\\\\CN(C(=O)C[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2ccccc23)C/C(=C\\\\c2ccccc2OC)C1=O'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd72855a-8310-4a5e-b5c8-7fe181ea8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgen_train = DataGenerator(X_train, y_train, seq_length=max_sequence_len, batch_size=128, data_augmentation=True)\n",
    "dgen_test = DataGenerator(X_test, y_test, seq_length=max_sequence_len, batch_size=128, data_augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d580353-ccfc-4b41-898d-2eaae3c5f8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datagen.DataGenerator at 0x7f095a9d9850>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgen_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bf28e8f-b29e-4b60-b7a2-4f08ff5a547b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\r"
     ]
    }
   ],
   "source": [
    "for i, (X_b, y_b) in enumerate(dgen_test):\n",
    "    print(f'{i}\\r', end='')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9a05124-5e24-460d-af7c-ae1f15faff91",
   "metadata": {},
   "source": [
    "X_b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85941430-2534-4d7d-ba52-d934a31c1bf6",
   "metadata": {},
   "source": [
    "# Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd5d1bf-4640-4cbc-acd3-72881ddcc07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 204, 128)          5504      \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 250)               254000    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              251000    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1000)              4000      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 515505 (1.97 MB)\n",
      "Trainable params: 513505 (1.96 MB)\n",
      "Non-trainable params: 2000 (7.81 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 41s 901ms/step - loss: 11.8421 - RMSE: 2.4231 - val_loss: 31.9720 - val_RMSE: 5.3499 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 29s 790ms/step - loss: 5.5386 - RMSE: 1.6939 - val_loss: 28.5911 - val_RMSE: 5.1352 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 29s 794ms/step - loss: 4.3570 - RMSE: 1.5965 - val_loss: 26.4649 - val_RMSE: 4.9947 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 27s 742ms/step - loss: 3.8891 - RMSE: 1.5746 - val_loss: 24.4028 - val_RMSE: 4.8086 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 19s 513ms/step - loss: 3.5879 - RMSE: 1.5546 - val_loss: 23.2910 - val_RMSE: 4.7199 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 30s 820ms/step - loss: 3.2733 - RMSE: 1.5245 - val_loss: 21.9990 - val_RMSE: 4.5980 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 31s 875ms/step - loss: 3.1996 - RMSE: 1.5405 - val_loss: 20.2251 - val_RMSE: 4.4082 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 28s 776ms/step - loss: 3.0957 - RMSE: 1.5245 - val_loss: 17.6338 - val_RMSE: 4.1160 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 26s 729ms/step - loss: 2.9895 - RMSE: 1.5206 - val_loss: 16.9689 - val_RMSE: 4.0335 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 28s 785ms/step - loss: 2.8360 - RMSE: 1.5087 - val_loss: 14.5588 - val_RMSE: 3.7287 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, Dense, BatchNormalization, Activation, LSTM\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import RMSprop  # Import RMSprop optimizer\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError  # Import RMSE metric\n",
    "from tensorflow.keras.backend import square, mean  # Import backend functions\n",
    "\n",
    "# Build the sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "model.add(Embedding(input_dim=42 + 1, output_dim=128, input_length=204))  # Use seq_length here\n",
    "\n",
    "# Bidirectional LSTM layer with L2 regularization\n",
    "model.add(Bidirectional(LSTM(125, return_sequences=False, kernel_regularizer=l2(0.01))))\n",
    "\n",
    "# Dense layer with L2 regularization\n",
    "model.add(Dense(1000, kernel_regularizer=l2(0.01)))\n",
    "\n",
    "# Batch normalization layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Activation layer\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Output dense layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Learning rate scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# RMSE metric function\n",
    "def RMSE(y_true, y_pred):\n",
    "    return tf.sqrt(mean(square(y_pred - y_true)))\n",
    "\n",
    "# Compile the model with RMSE metric\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.001, clipvalue=0.1), loss='mse', metrics=[RMSE])\n",
    "\n",
    "# Instantiate the DataGenerator\n",
    "dgen_train = DataGenerator(X_train, y_train, seq_length=204, batch_size=128, data_augmentation=True)\n",
    "dgen_test = DataGenerator(X_test, y_test, seq_length=204, batch_size=128, data_augmentation=True)\n",
    "\n",
    "history = model.fit(dgen_train, epochs=50, validation_data=dgen_test, callbacks=[lr_scheduler, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0242588-eede-4e85-8b83-f207ea8ab757",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_eval = []\n",
    "y_t_eval = []\n",
    "for X_t, y_t in dgen_test:\n",
    "    X_test_eval = X_test_eval + [list(t) for t in X_t]\n",
    "    y_t_eval = y_t_eval + list(y_t)\n",
    "X_test_eval = np.array(X_test_eval)\n",
    "y_test = np.array(y_t_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1437cbf-fe44-4999-a44b-05cea765f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_eval.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0084fbb1-e83e-4808-99bf-1458f3ea3076",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382979a3-f299-4762-8b6d-10a6ea4d3c70",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fd5d60-841f-46c3-94b6-5755b4d548cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = 1 - ((y_test - y_pred.reshape(-1)) ** 2).sum() / ((y_test - y_test.mean()) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2bfabe-2e3e-40cf-a1e8-2d458ee7f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85262541-e04a-4ff2-b3e6-a47643db66f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/other_tests.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f683e18-c876-4f7c-93ea-a33d495dcdaa",
   "metadata": {},
   "source": [
    "# Load model (solo si se grabo el modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285c8740-f0bb-4237-8593-ff9b815de0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2168984f-770c-436e-92da-c1344b1d3abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = load_model(filename, custom_objects={'R2': R2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a9d7d8-41e0-44a0-a8b9-02157a11f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_loaded.predict(X_test_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c63493-3f25-4383-9654-58ee62aa3ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = 1 - ((y_test - y_pred.reshape(-1)) ** 2).sum() / ((y_test - y_test.mean()) ** 2).sum()\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1a6260-e31f-4e5e-a923-ce67bf31152f",
   "metadata": {},
   "source": [
    "# Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd9d7e6-2789-459e-b9dd-593e10847fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "ax = sns.regplot(x=y_test, y=y_pred, scatter_kws={'alpha':0.4})\n",
    "ax.set_xlabel('Experimental pIC50', fontsize='large', fontweight='bold')\n",
    "ax.set_ylabel('Predicted pIC50', fontsize='large', fontweight='bold')\n",
    "ax.set_xlim(0, 12)\n",
    "ax.set_ylim(0, 12)\n",
    "ax.figure.set_size_inches(5, 5)\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
