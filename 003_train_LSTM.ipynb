{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21bee0a3-79a7-43b2-9ac2-15cad5630e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08544474-e883-4105-bcc3-9f3f9f014079",
   "metadata": {},
   "source": [
    "# Modelo Recurrentes con Embeddings a nivel de caracter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "353a2d75-f0f4-4563-9842-c68d77118161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/acetylcholinesterase_02_bioactivity_data_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1554fa5-d9ee-456c-be20-80571e319fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_chembl_id</th>\n",
       "      <th>canonical_smiles</th>\n",
       "      <th>standard_value</th>\n",
       "      <th>standard_value_norm</th>\n",
       "      <th>pIC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL133897</td>\n",
       "      <td>CCOc1nn(-c2cccc(OCc3ccccc3)c2)c(=O)o1</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>6.124939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL336398</td>\n",
       "      <td>O=C(N1CCCCC1)n1nc(-c2ccc(Cl)cc2)nc1SCC1CC1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL131588</td>\n",
       "      <td>CN(C(=O)n1nc(-c2ccc(Cl)cc2)nc1SCC(F)(F)F)c1ccccc1</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>4.301030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL130628</td>\n",
       "      <td>O=C(N1CCCCC1)n1nc(-c2ccc(Cl)cc2)nc1SCC(F)(F)F</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL130478</td>\n",
       "      <td>CSc1nc(-c2ccc(OC(F)(F)F)cc2)nn1C(=O)N(C)C</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>6.096910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  molecule_chembl_id                                   canonical_smiles  \\\n",
       "0       CHEMBL133897              CCOc1nn(-c2cccc(OCc3ccccc3)c2)c(=O)o1   \n",
       "1       CHEMBL336398         O=C(N1CCCCC1)n1nc(-c2ccc(Cl)cc2)nc1SCC1CC1   \n",
       "2       CHEMBL131588  CN(C(=O)n1nc(-c2ccc(Cl)cc2)nc1SCC(F)(F)F)c1ccccc1   \n",
       "3       CHEMBL130628      O=C(N1CCCCC1)n1nc(-c2ccc(Cl)cc2)nc1SCC(F)(F)F   \n",
       "4       CHEMBL130478          CSc1nc(-c2ccc(OC(F)(F)F)cc2)nn1C(=O)N(C)C   \n",
       "\n",
       "   standard_value  standard_value_norm     pIC50  \n",
       "0           750.0                750.0  6.124939  \n",
       "1           100.0                100.0  7.000000  \n",
       "2         50000.0              50000.0  4.301030  \n",
       "3           300.0                300.0  6.522879  \n",
       "4           800.0                800.0  6.096910  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2985df76-23b9-45a8-83ed-ce8ae510219f",
   "metadata": {},
   "source": [
    "# Canonical_smiles To secuence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87e524d2-e7e9-4d3b-b1f1-b62254a0bc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 06:32:26.813894: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-31 06:32:26.817384: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-31 06:32:26.905278: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-31 06:32:26.908402: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-31 06:32:27.891046: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524afd5-79ed-433d-827b-ac04510ae8ad",
   "metadata": {},
   "source": [
    "Utilizando Tokenizer y pad_sequences de keras a nivel de caracter, obtener la entrada tokenizada. Por ejemplo:\n",
    "\n",
    "**El smiles**:\n",
    "\n",
    "'C[C@@]12CC[C@H]3[C@]4(C)CCC[C@@]5(C)C(=O)OCC[N+](C)(C)CCCCCCCCC[N+](C)(C)CCOC(=O)[C@]6(C)CCC[C@]7(C)[C@@H]6CC[C@@]68C[C@@H](OC(=O)CCCCCCCCC(=O)O[C@@H]1C[C@@]3(CC[C@@H]45)C2)[C@@](C)(CC[C@@H]76)C8.[Br-].[Br-]'\n",
    "\n",
    "**Tendría que quedar algo asi (puede que no sea exacto):**\n",
    "\n",
    "array([ 2, 11,  2, 13, 13, 12,  5,  7,  2,  2, 11,  2, 13, 16, 12, 10, 11,\n",
    "        2, 13, 12, 15,  3,  2,  4,  2,  2,  2, 11,  2, 13, 13, 12, 23,  3,\n",
    "        2,  4,  2,  3,  9,  6,  4,  6,  2,  2, 11,  8, 21, 12,  3,  2,  4,\n",
    "        3,  2,  4,  2,  2,  2,  2,  2,  2,  2,  2,  2, 11,  8, 21, 12,  3,\n",
    "        2,  4,  3,  2,  4,  2,  2,  6,  2,  3,  9,  6,  4, 11,  2, 13, 12,\n",
    "       30,  3,  2,  4,  2,  2,  2, 11,  2, 13, 12, 35,  3,  2,  4, 11,  2,\n",
    "       13, 13, 16, 12, 30,  2,  2, 11,  2, 13, 13, 12, 30, 36,  2, 11,  2,\n",
    "       13, 13, 16, 12,  3,  6,  2,  3,  9,  6,  4,  2,  2,  2,  2,  2,  2,\n",
    "        2,  2,  2,  3,  9,  6,  4,  6, 11,  2, 13, 13, 16, 12,  5,  2, 11,\n",
    "        2, 13, 13, 12, 10,  3,  2,  2, 11,  2, 13, 13, 16, 12, 15, 23,  4,\n",
    "        2,  7,  4, 11,  2, 13, 13, 12,  3,  2,  4,  3,  2,  2, 11,  2, 13,\n",
    "       13, 16, 12, 35, 30,  4,  2, 36, 20, 11, 25, 26, 17, 12, 20, 11, 25,\n",
    "       26, 17, 12], dtype=int32)\n",
    "       \n",
    "\n",
    "**Otro ejemplo:**\n",
    "smiles: 'NC(=O)O'\n",
    "\n",
    "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 8, 2, 3, 9, 6, 4, 6], dtype=int32)\n",
    "\n",
    "**Tener en cuenta:**\n",
    "\n",
    "- Ver cuanta es la máxima longitud para agregar el padding correspondiente\n",
    "- En el ejemplo se agrego padding a la izquierda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07f8fff5-c1f6-48d6-9e19-ee5defde20b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_idx = df['canonical_smiles'].apply(len).argmax()\n",
    "min_len_idx = df['canonical_smiles'].apply(len).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a21da0d-f5cd-4c5f-a95c-94b9a1c9c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sequence_length = df['canonical_smiles'].apply(len).min()\n",
    "max_sequence_length = df['canonical_smiles'].apply(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9eaa10c-da25-4386-b332-ca86528c7341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "703325ab-0193-4bf5-9b66-a880d7bc346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['canonical_smiles']\n",
    "y = df['pIC50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09894d86-4408-469c-b1f9-60f6d7218b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementar tokenización y guardar en X_seq_pad el dataset tokenizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5028a561-00e6-4462-81dd-c1f25e44cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Extract canonical smiles from the DataFrame and labels\n",
    "canonical_smiles = X.tolist()\n",
    "labels = y.tolist()\n",
    "\n",
    "# Initialize the Tokenizer\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "\n",
    "# Fit the tokenizer on the canonical smiles\n",
    "tokenizer.fit_on_texts(canonical_smiles)\n",
    "\n",
    "# Tokenize and pad the canonical smiles sequences\n",
    "canonical_smiles_tokenized = tokenizer.texts_to_sequences(canonical_smiles)\n",
    "max_sequence_length = max(map(len, canonical_smiles_tokenized))\n",
    "canonical_smiles_padded = pad_sequences(canonical_smiles_tokenized, \n",
    "                                        maxlen=max_sequence_length)\n",
    "\n",
    "# Convert labels to a numpy array\n",
    "labels_array = np.array(labels)\n",
    "\n",
    "# Convert padded sequences to a numpy array\n",
    "X_seq_pad = np.array(canonical_smiles_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9233351c-7a53-464c-beaf-89d043cd8719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_seq_pad.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9b3f66e-8ee9-4d05-8835-39645fd68920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find rows with inf values\n",
    "# rows_with_inf = np.any(np.isinf(X_seq_pad), axis=1)\n",
    "\n",
    "# # Remove rows with inf values\n",
    "# X_seq_pad = X_seq_pad[~rows_with_inf]\n",
    "\n",
    "# X_seq_pad.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8557166f-c696-48d7-9764-7414f62fbe27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 6, 1, 4, 1, 7, 1, 2, 6, 1, 9, 1, 4, 1, 1, 1, 1, 9,\n",
       "       3, 1, 1, 1, 1, 7], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_seq_pad[200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4233710d-9274-4dae-b22d-cf42b57ad862",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce7a95e6-2486-42fb-97fb-865e3fd6a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcb9840f-2f41-45be-99a5-f05f3ab73ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to a numpy array\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq_pad, labels_array, test_size=0.2, random_state=999)\n",
    "X_train = np.delete(X_train,slice(4100,4150),axis=0)\n",
    "y_train = np.delete(y_train,slice(4100,4150),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ad17134-3e15-42d1-b8c9-0c793169e145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4875, 4875, 1232, 1232)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train), len(X_test) , len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85941430-2534-4d7d-ba52-d934a31c1bf6",
   "metadata": {},
   "source": [
    "# Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bd5d1bf-4640-4cbc-acd3-72881ddcc07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bf115a2-9f1b-42b8-9b62-59728f1da977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métrica\n",
    "def R2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92d30b68-3110-459c-887d-a06f056d067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_size = # Completar largo del vocabulario\n",
    "vocab_size = len(list(tokenizer.word_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6166a72b-ccd1-459c-a3a1-fa43bf31a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = len(max(X_seq_pad, key=len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc91cd42-b885-4ab5-b348-57296b0c0d10",
   "metadata": {},
   "source": [
    "# Armar modelo en keras de LSTM\n",
    "El de abajo es un ejemplo propuesto pero puede armar otro similar (siempre con LSTM o GRU)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9883ed67-e2d9-412a-8f8b-1e463df69ed8",
   "metadata": {},
   "source": [
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "embedding (Embedding)        (None, 207, 64)           2496      \n",
    "_________________________________________________________________\n",
    "bidirectional (Bidirectional (None, 200)               132000    \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 50)                10050     \n",
    "_________________________________________________________________\n",
    "batch_normalization (BatchNo (None, 50)                200       \n",
    "_________________________________________________________________\n",
    "activation (Activation)      (None, 50)                0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 1)                 51        \n",
    "=================================================================\n",
    "Total params: 144,797\n",
    "Trainable params: 144,697\n",
    "Non-trainable params: 100\n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "771e04f3-b991-4ffb-be76-0d2075494f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  5,\n",
       "        1,  2,  8,  5,  3,  1,  4,  8,  1,  2,  1,  3,  5,  1,  7,  6,  1,\n",
       "        9,  1,  2,  1,  2,  6,  3,  1,  7, 10,  1, 12, 14, 11,  4,  1,  4,\n",
       "        1,  1,  1,  1,  2,  5,  1,  3,  1,  4,  3,  1,  1,  1,  1,  1,  9],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d05209e0-5358-40c0-b806-2e98367e9f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 204, 128)          4352      \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 250)               254000    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              251000    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1000)              4000      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 514353 (1.96 MB)\n",
      "Trainable params: 512353 (1.95 MB)\n",
      "Non-trainable params: 2000 (7.81 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, Dense, BatchNormalization, Activation, LSTM\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Build the sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=X_seq_pad.shape[1]))\n",
    "\n",
    "# Bidirectional LSTM layer with L2 regularization\n",
    "model.add(Bidirectional(LSTM(125, return_sequences=False, kernel_regularizer=l2(0.01))))\n",
    "\n",
    "# Dense layer with L2 regularization\n",
    "model.add(Dense(1000, kernel_regularizer=l2(0.01)))\n",
    "\n",
    "# Batch normalization layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Activation layer\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Output dense layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Learning rate scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001, clipvalue=0.1), loss='mse', metrics=[R2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62c3f792-f413-4150-8ebf-1f59c5fb986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp = ModelCheckpoint('models/best_model_{epoch}', save_best_only=True, save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f37ab4e-0e3a-44c6-a572-ba5c67930c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "77/77 [==============================] - ETA: 0s - loss: 12.9089 - R2: -2.0417INFO:tensorflow:Assets written to: models/best_model_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/best_model_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 38s 423ms/step - loss: 12.9089 - R2: -2.0417 - val_loss: 22.8238 - val_R2: -7.3676 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "77/77 [==============================] - ETA: 0s - loss: 5.0583 - R2: -0.0770INFO:tensorflow:Assets written to: models/best_model_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/best_model_2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 31s 409ms/step - loss: 5.0583 - R2: -0.0770 - val_loss: 17.2592 - val_R2: -5.4422 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "77/77 [==============================] - 20s 261ms/step - loss: 4.0508 - R2: 0.0504 - val_loss: 20.2986 - val_R2: -6.9690 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "77/77 [==============================] - ETA: 0s - loss: 3.4432 - R2: 0.1306INFO:tensorflow:Assets written to: models/best_model_4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/best_model_4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 34s 442ms/step - loss: 3.4432 - R2: 0.1306 - val_loss: 11.7249 - val_R2: -3.4113 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "77/77 [==============================] - ETA: 0s - loss: 3.0412 - R2: 0.1827INFO:tensorflow:Assets written to: models/best_model_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/best_model_5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 33s 428ms/step - loss: 3.0412 - R2: 0.1827 - val_loss: 8.4440 - val_R2: -2.1023 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "77/77 [==============================] - ETA: 0s - loss: 2.6570 - R2: 0.2304INFO:tensorflow:Assets written to: models/best_model_6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/best_model_6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 41s 534ms/step - loss: 2.6570 - R2: 0.2304 - val_loss: 6.0433 - val_R2: -1.1618 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "77/77 [==============================] - ETA: 0s - loss: 2.5068 - R2: 0.2231INFO:tensorflow:Assets written to: models/best_model_7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/best_model_7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 50s 649ms/step - loss: 2.5068 - R2: 0.2231 - val_loss: 4.5180 - val_R2: -0.5864 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "77/77 [==============================] - ETA: 0s - loss: 2.2317 - R2: 0.2752INFO:tensorflow:Assets written to: models/best_model_8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/best_model_8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 36s 468ms/step - loss: 2.2317 - R2: 0.2752 - val_loss: 3.2257 - val_R2: -0.0956 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "77/77 [==============================] - ETA: 0s - loss: 2.1034 - R2: 0.3032INFO:tensorflow:Assets written to: models/best_model_9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/best_model_9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 48s 633ms/step - loss: 2.1034 - R2: 0.3032 - val_loss: 2.8827 - val_R2: 0.0107 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "77/77 [==============================] - 32s 411ms/step - loss: 2.0258 - R2: 0.2985 - val_loss: 3.0620 - val_R2: -0.1286 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "77/77 [==============================] - ETA: 0s - loss: 1.9083 - R2: 0.3196INFO:tensorflow:Assets written to: models/best_model_11/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/best_model_11/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 42s 548ms/step - loss: 1.9083 - R2: 0.3196 - val_loss: 2.4671 - val_R2: 0.1133 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "77/77 [==============================] - ETA: 0s - loss: 1.8839 - R2: 0.3069INFO:tensorflow:Assets written to: models/best_model_12/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/best_model_12/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 46s 597ms/step - loss: 1.8839 - R2: 0.3069 - val_loss: 2.0058 - val_R2: 0.2928 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "77/77 [==============================] - 26s 341ms/step - loss: 1.8222 - R2: 0.3182 - val_loss: 2.4778 - val_R2: 0.0822 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "77/77 [==============================] - 38s 492ms/step - loss: 1.7760 - R2: 0.2949 - val_loss: 2.1160 - val_R2: 0.2052 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "77/77 [==============================] - 39s 501ms/step - loss: 1.8636 - R2: 0.2824 - val_loss: 2.9416 - val_R2: -0.1164 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "77/77 [==============================] - ETA: 0s - loss: 1.7193 - R2: 0.3347INFO:tensorflow:Assets written to: models/best_model_16/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/best_model_16/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 54s 701ms/step - loss: 1.7193 - R2: 0.3347 - val_loss: 1.8921 - val_R2: 0.2993 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "77/77 [==============================] - 34s 438ms/step - loss: 1.7197 - R2: 0.3320 - val_loss: 2.2852 - val_R2: 0.1559 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "77/77 [==============================] - 36s 470ms/step - loss: 1.7576 - R2: 0.3068 - val_loss: 2.5903 - val_R2: 0.0150 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "77/77 [==============================] - 38s 489ms/step - loss: 1.6915 - R2: 0.3379 - val_loss: 2.1088 - val_R2: 0.2315 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "77/77 [==============================] - 25s 327ms/step - loss: 1.6646 - R2: 0.3428 - val_loss: 2.3696 - val_R2: 0.1098 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "77/77 [==============================] - 32s 417ms/step - loss: 1.7012 - R2: 0.3290 - val_loss: 2.0539 - val_R2: 0.2191 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "21/77 [=======>......................] - ETA: 13s - loss: 1.5511 - R2: 0.3866"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test), callbacks=[lr_scheduler, early_stopping,mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0084fbb1-e83e-4808-99bf-1458f3ea3076",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382979a3-f299-4762-8b6d-10a6ea4d3c70",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fd5d60-841f-46c3-94b6-5755b4d548cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = 1 - ((y_test - y_pred.reshape(-1)) ** 2).sum() / ((y_test - y_test.mean()) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2bfabe-2e3e-40cf-a1e8-2d458ee7f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2\n",
    "# 0.4984533246797399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85262541-e04a-4ff2-b3e6-a47643db66f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/final_v2.h5', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f683e18-c876-4f7c-93ea-a33d495dcdaa",
   "metadata": {},
   "source": [
    "# Load model (solo si se grabo el modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285c8740-f0bb-4237-8593-ff9b815de0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2168984f-770c-436e-92da-c1344b1d3abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = load_model('models/final_v1.h5', custom_objects={'R2': R2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a9d7d8-41e0-44a0-a8b9-02157a11f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_loaded.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ab60bf-7b98-4f46-b1dd-b08b5fbf8bed",
   "metadata": {},
   "source": [
    "¿Hasta que valores de r2 logró?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c07210-469b-47a5-a86c-d413a55f9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = 1 - ((y_test - y_pred.reshape(-1)) ** 2).sum() / ((y_test - y_test.mean()) ** 2).sum()\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1a6260-e31f-4e5e-a923-ce67bf31152f",
   "metadata": {},
   "source": [
    "# Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd9d7e6-2789-459e-b9dd-593e10847fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "ax = sns.regplot(x=y_test, y=y_pred, scatter_kws={'alpha':0.4})\n",
    "ax.set_xlabel('Experimental pIC50', fontsize='large', fontweight='bold')\n",
    "ax.set_ylabel('Predicted pIC50', fontsize='large', fontweight='bold')\n",
    "ax.set_xlim(0, 12)\n",
    "ax.set_ylim(0, 12)\n",
    "ax.figure.set_size_inches(5, 5)\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
